{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/verl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "from typing import List, Dict, Tuple, Any\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset, load_dataset\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer\n",
    "from unidiff import PatchSet, UnidiffParseError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2248 examples [00:01, 1514.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"parquet\", data_files=\"data/swe-oracle/search-replace/test.parquet\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_data = load_dataset(\"data/princeton-nlp/SWE-bench_Verified\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "astropy__astropy-13398\n"
     ]
    }
   ],
   "source": [
    "verified_instance_ids = verified_data[\"instance_id\"]\n",
    "for instance_id in verified_instance_ids:\n",
    "    if instance_id not in dataset[\"instance_id\"]:\n",
    "        print(instance_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2248/2248 [00:00<00:00, 3962.76 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  3.15ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90412956"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verfied_data = dataset.filter(lambda x: x[\"instance_id\"] in verified_instance_ids)\n",
    "verfied_data.to_parquet(\"data/swe-verified-eval/search-replace.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 498 examples [00:00, 890.89 examples/s] \n"
     ]
    }
   ],
   "source": [
    "outputs = load_dataset(\"json\", data_files=\"outputs/swe-verified-eval/search-replace/deepseek-chat-temp-0.0-tokens-4096-maxlen-131072_score_0.1138.jsonl\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verl.utils.reward_score.swe_rl.original import extract_thought_solution, parse_search_replace, apply_code_change, get_normalized_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "\n",
    "pred = outputs[idx][\"prediction\"]\n",
    "file_names = outputs[idx][\"extra_info\"][\"file_names\"]\n",
    "file_contents = outputs[idx][\"extra_info\"][\"file_contents\"]\n",
    "thought, solution = extract_thought_solution(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dict = {name: content for name, content in zip(file_names, file_contents)}\n",
    "code_changes = parse_search_replace(solution)\n",
    "pred_dict = apply_code_change(code_dict, code_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def generate_patch_from_dicts(original_dict, pred_dict):\n",
    "    patch_lines = []\n",
    "\n",
    "    # Only generate diffs for files that exist in both\n",
    "    for file_path in original_dict.keys() & pred_dict.keys():\n",
    "        old_content = original_dict[file_path].splitlines(keepends=True)\n",
    "        new_content = pred_dict[file_path].splitlines(keepends=True)\n",
    "        diff = difflib.unified_diff(\n",
    "            old_content,\n",
    "            new_content,\n",
    "            fromfile=f\"a/{file_path}\",\n",
    "            tofile=f\"b/{file_path}\",\n",
    "        )\n",
    "        patch_lines.extend(diff)\n",
    "\n",
    "    return \"\".join(patch_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- a/astropy/timeseries/core.py\n",
      "+++ b/astropy/timeseries/core.py\n",
      "@@ -68,17 +68,22 @@\n",
      " \n",
      "             plural = 's' if len(required_columns) > 1 else ''\n",
      " \n",
      "-            if not self._required_columns_relax and len(self.colnames) == 0:\n",
      "+            if not self._required_columns_relax:\n",
      "+                if len(self.colnames) == 0:\n",
      "+                    raise ValueError(\"{} object is invalid - expected columns {} \"\n",
      "+                                   \"but time series has no columns\"\n",
      "+                                   .format(self.__class__.__name__, required_columns))\n",
      "+                \n",
      "+                missing_columns = set(required_columns) - set(self.colnames)\n",
      "+                if missing_columns:\n",
      "+                    plural = 's' if len(missing_columns) > 1 else ''\n",
      "+                    raise ValueError(\"{} object is invalid - missing required column{}: {}\"\n",
      "+                                   .format(self.__class__.__name__, plural, sorted(missing_columns)))\n",
      " \n",
      "-                raise ValueError(\"{} object is invalid - expected '{}' \"\n",
      "-                                 \"as the first column{} but time series has no columns\"\n",
      "-                                 .format(self.__class__.__name__, required_columns[0], plural))\n",
      "-\n",
      "-            elif self.colnames[:len(required_columns)] != required_columns:\n",
      "-\n",
      "-                raise ValueError(\"{} object is invalid - expected '{}' \"\n",
      "-                                 \"as the first column{} but found '{}'\"\n",
      "-                                 .format(self.__class__.__name__, required_columns[0], plural, self.colnames[0]))\n",
      "+            if self.colnames[:len(required_columns)] != required_columns:\n",
      "+                raise ValueError(\"{} object is invalid - expected columns {} \"\n",
      "+                               \"to appear first, but found {}\"\n",
      "+                               .format(self.__class__.__name__, required_columns, self.colnames[:len(required_columns)]))\n",
      " \n",
      "             if (self._required_columns_relax\n",
      "                     and self._required_columns == self.colnames[:len(self._required_columns)]):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate_patch_from_dicts(code_dict, pred_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
